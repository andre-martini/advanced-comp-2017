{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Work on this before the next lecture on 24 April. We will talk about questions, comments, and solutions during the exercise after the third lecture.\n",
    "\n",
    "Please do form study groups! When you do, make sure you can explain everything in your own words, do not simply copy&paste from others.\n",
    "\n",
    "The solutions to a lot of these problems can probably be found with Google. Please don't. You will not learn a lot by copy&pasting from the internet.\n",
    "\n",
    "If you want to get credit/examination on this course please upload your work to **your GitHub repository** for this course **before** the next lecture starts and post a link to your repository [in this thread](https://github.com/wildtreetech/advanced-comp-2017/issues/3). If you worked on things together with others please add their names to the notebook so we can see who formed groups.\n",
    "\n",
    "---\n",
    "\n",
    "These are some useful default imports for plotting and [`numpy`](http://www.numpy.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Finding analytic gradients of expressions. Use the backprop framework we built in the lecture to compute the analytic gradient of an expression. \n",
    "\n",
    "For example, using the expression: $f(x) = \\sin(x^2)$: implement a module for $\\sin(x)$, build the graph representing the function, plot the expression as well as the gradient as a function of $x$.\n",
    "\n",
    "* add a new operation (e.g. $\\sin, \\cos, \\exp, x^y$, ...) to the `Addition` and `Multiply` modules.\n",
    "* build a new expression using the available expressions\n",
    "* plot your expression as well as its gradient\n",
    "* compare the gradient to one you worked out by hand (or some other software package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Use the circle data set from exercise 1 and build a neural network classifier that can solve the problem (scikit-learn provides a `MLPClassifier` classifier that implements a neural network). Comment on:\n",
    "\n",
    "* what is the minimum number of layers\n",
    "* what is the minimum width of each layer\n",
    "* does the answer change if you provide polynomial features?\n",
    "* is there a difference between using the `tanh` and `ReLU` activation functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Question 2.5\n",
    "\n",
    "Use the spiral data set build a neural network classifier that can solve the problem (scikit-learn provides a `MLPClassifier` classifier that implements a neural network). Comment on:\n",
    "\n",
    "* what is the minimum number of layers\n",
    "* what is the minimum width of each layer\n",
    "* is there a difference between using the `tanh` and `ReLU` activation functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_spiral():\n",
    "    N = 100 # number of points per class\n",
    "    K = 3 # number of classes\n",
    "    X = np.zeros((N*K, 2)) # data matrix (each row = single example)\n",
    "    y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "    for j in range(K):\n",
    "        ix = range(N*j, N*(j+1))\n",
    "        r = np.linspace(0.0, 1, N) # radius\n",
    "        t = np.linspace(j*4, (j+1)*4, N) + np.random.randn(N)*0.2 # theta\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Question 3\n",
    "\n",
    "UThis is a regression problem. Use a gradient boosted tree regressor (tune the `max_depth`, `learning_rate` and `n_estimators` parameters) to study the importance of the different features as well as the partial dependence of the output on individual features as well as pairs of features.\n",
    "\n",
    "* can you identify uninformative features?\n",
    "* which features interact additively?\n",
    "* can you interpret the partial dependence plots \n",
    "\n",
    "(Help: `rgr = GradientBoostingRegressor(n_estimators=200, max_depth=2, learning_rate=0.1)\n",
    "` seems to work quite well)\n",
    "(Help: to produce 1D and 2D partial dependence plots pass `[0,1, (0,1)]` as the `features` argument of `plot_partial_dependence`. More details in the functions documentation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "def make_data(n_samples=800, n_features=8, noise=0.2, random_state=2):\n",
    "    generator = check_random_state(random_state)\n",
    "\n",
    "    X = generator.rand(n_samples, n_features)\n",
    "    y = 10 * (X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 \\\n",
    "        + 10 * X[:, 3] + 10 * X[:, 4] + noise * generator.randn(n_samples)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X,y = make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## (Bonus) Question 4\n",
    "\n",
    "House prices in California. Use a gradient boosted regression tree model to build a model that can predict house prices in California (`GradientBoostingRegressor` is your friend).\n",
    "\n",
    "Plot each of the features as a scatter plot with the target to learn about each variable. You can also make a plot of two features and use the target as colour.\n",
    "\n",
    "Fit a model and tune the model complexity using a training and test data set.\n",
    "\n",
    "Explore the feature importances and partial dependences that are important to the house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "\n",
    "# if the above doesn't work, download `cal_housing_py3.pkl` from the GitHub repository\n",
    "# and adjust the path to the downloaded file which is passed to `load()`\n",
    "# uncomment the following lines\n",
    "#from sklearn.externals.joblib import load\n",
    "#d = load('/home/username/Downloads/cal_housing_py3.pkz')\n",
    "#X, y = d[:,1:], d[:,0]/100000\n",
    "#X[:, 2] /= X[:, 5]\n",
    "#X[:, 3] /= X[:, 5]\n",
    "#X[:, 5] = X[:, 4] / X[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
